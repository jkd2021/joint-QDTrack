[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/prototypical-cross-attention-networks-for/multi-object-tracking-and-segmentation-on-2)](https://paperswithcode.com/sota/multi-object-tracking-and-segmentation-on-2?p=prototypical-cross-attention-networks-for)
# Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation

This is the offical implementation of paper [PCAN](https://papers.nips.cc/paper/2021/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf) for MOTS. PCAN is also served as the baseline method in [BDD100K tracking challenges](https://www.bdd100k.com/challenges/cvpr2022/) at CVPR 2022.  

We also present a [trailer](https://www.youtube.com/watch?v=hhAC2H0fmP8) that consists of method illustrations and tracking & segmentation visualizations. Our project website contains more information: [vis.xyz/pub/pcan](https://www.vis.xyz/pub/pcan/).



## Installation
Please refer to [INSTALL.md](docs/INSTALL.md) for installation instructions.

## Usages

## References
```
@inproceedings{pang2021quasi,
  title={Quasi-dense similarity learning for multiple object tracking},
  author={Pang, Jiangmiao and Qiu, Linlu and Li, Xia and Chen, Haofeng and Li, Qi and Darrell, Trevor and Yu, Fisher},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={164--173},
  year={2021}
}
@inproceedings{pcan,
  title={Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation},
  author={Ke, Lei and Li, Xia and Danelljan, Martin and Tai, Yu-Wing and Tang, Chi-Keung and Yu, Fisher},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}
